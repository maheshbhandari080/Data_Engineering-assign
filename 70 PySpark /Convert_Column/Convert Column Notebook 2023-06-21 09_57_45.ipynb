{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.master(\"local[1]\") \\\n                    .appName('SparkByExamples.com') \\\n                    .getOrCreate()\n\ndata = [(\"James\",\"Smith\",\"USA\",\"CA\"),(\"Michael\",\"Rose\",\"USA\",\"NY\"), \\\n    (\"Robert\",\"Williams\",\"USA\",\"CA\"),(\"Maria\",\"Jones\",\"USA\",\"FL\") \\\n  ]\ncolumns=[\"firstname\",\"lastname\",\"country\",\"state\"]\ndf=spark.createDataFrame(data=data,schema=columns)\ndf.show()\nprint(df.collect())\n\nstates1=df.rdd.map(lambda x: x[3]).collect()\nprint(states1)\n#['CA', 'NY', 'CA', 'FL']\nfrom collections import OrderedDict \nres = list(OrderedDict.fromkeys(states1)) \nprint(res)\n#['CA', 'NY', 'FL']\n\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"5dc67a11-2a1e-48b5-a4b3-848e663a8ba4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+--------+-------+-----+\n|firstname|lastname|country|state|\n+---------+--------+-------+-----+\n|    James|   Smith|    USA|   CA|\n|  Michael|    Rose|    USA|   NY|\n|   Robert|Williams|    USA|   CA|\n|    Maria|   Jones|    USA|   FL|\n+---------+--------+-------+-----+\n\n[Row(firstname='James', lastname='Smith', country='USA', state='CA'), Row(firstname='Michael', lastname='Rose', country='USA', state='NY'), Row(firstname='Robert', lastname='Williams', country='USA', state='CA'), Row(firstname='Maria', lastname='Jones', country='USA', state='FL')]\n['CA', 'NY', 'CA', 'FL']\n['CA', 'NY', 'FL']\n"]}],"execution_count":0},{"cell_type":"code","source":["#Example 2\nstates2=df.rdd.map(lambda x: x.state).collect()\nprint(states2)\n#['CA', 'NY', 'CA', 'FL']\n\nstates3=df.select(df.state).collect()\nprint(states3)\n#[Row(state='CA'), Row(state='NY'), Row(state='CA'), Row(state='FL')]\n\nstates4=df.select(df.state).rdd.flatMap(lambda x: x).collect()\nprint(states4)\n#['CA', 'NY', 'CA', 'FL']\n\nstates5=df.select(df.state).toPandas()['state']\nstates6=list(states5)\nprint(states6)\n#['CA', 'NY', 'CA', 'FL']\n\npandDF=df.select(df.state,df.firstname).toPandas()\nprint(list(pandDF['state']))\nprint(list(pandDF['firstname']))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"7ab416ba-d44e-4461-ba5f-227c9ace498f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["['CA', 'NY', 'CA', 'FL']\n[Row(state='CA'), Row(state='NY'), Row(state='CA'), Row(state='FL')]\n['CA', 'NY', 'CA', 'FL']\n['CA', 'NY', 'CA', 'FL']\n['CA', 'NY', 'CA', 'FL']\n['James', 'Michael', 'Robert', 'Maria']\n"]}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Convert Column Notebook 2023-06-21 09:57:45","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
